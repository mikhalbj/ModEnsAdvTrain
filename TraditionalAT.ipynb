{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a21f0a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.utils.data as td\n",
    "import random, time\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import PIL.Image as Image\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchvision.utils as vutils\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b2897bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size_cifar = 50\n",
    "\n",
    "def cifar_loaders(batch_size, shuffle_test=False): \n",
    "    data_dir = './data'\n",
    "    train = datasets.CIFAR10(data_dir, train=True, download=True, \n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ]))\n",
    "    # Once you have downloaded the data by setting download=True, you can\n",
    "    # change download=True to download=False\n",
    "    test = datasets.CIFAR10(data_dir, train=False, \n",
    "        transform=transforms.Compose([transforms.ToTensor()]))\n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size,\n",
    "        shuffle=True, pin_memory=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size,\n",
    "        shuffle=shuffle_test, pin_memory=True)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "train_cifar_loader, test_cifar_loader = cifar_loaders(batch_size_cifar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e01c018c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vgg import vgg11_bn\n",
    "vgg11 = vgg11_bn(pretrained=True).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a96daa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial_update(images,labels, model,loss, epsilon, step_size, n_iter):\n",
    "  delta = torch.zeros(images.size()).to(device)\n",
    "  image_mod = (images+delta)\n",
    "  for i in range(n_iter):\n",
    "    image_mod.requires_grad = True\n",
    "    preds = model(image_mod)\n",
    "    loss_val = loss(preds,labels)\n",
    "    if i == 0:\n",
    "      standard_loss = loss_val.item()\n",
    "    loss_val.backward()\n",
    "    gradient = torch.sign(image_mod.grad.data)\n",
    "    delta = delta + step_size*gradient\n",
    "    delta = delta.clamp(min=-epsilon, max=epsilon)\n",
    "    image_mod = (images+delta).clamp(min=0,max=1)\n",
    "  return (image_mod, standard_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02da9868-de0c-4c0b-9514-0d59c4e8c5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg11_adv = vgg11_bn(pretrained=True).to(device)\n",
    "\n",
    "optimizer = optim.Adam(vgg11_adv.parameters(),lr=1e-5)\n",
    "num_epochs = 256\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "loss_standard = np.zeros(num_epochs)\n",
    "loss_adv = np.zeros(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1e37a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Adversarial Loss - 2.587, Loss - 1.498\n",
      "Epoch 1: Adversarial Loss - 2.265, Loss - 1.245\n",
      "Epoch 2: Adversarial Loss - 2.184, Loss - 1.095\n",
      "Epoch 3: Adversarial Loss - 2.122, Loss - 0.984\n",
      "Epoch 4: Adversarial Loss - 2.054, Loss - 0.871\n",
      "Epoch 5: Adversarial Loss - 1.981, Loss - 0.767\n",
      "Epoch 6: Adversarial Loss - 1.894, Loss - 0.661\n",
      "Epoch 7: Adversarial Loss - 1.807, Loss - 0.566\n",
      "Epoch 8: Adversarial Loss - 1.709, Loss - 0.482\n",
      "Epoch 9: Adversarial Loss - 1.609, Loss - 0.409\n",
      "Epoch 10: Adversarial Loss - 1.531, Loss - 0.351\n",
      "Epoch 11: Adversarial Loss - 1.446, Loss - 0.301\n",
      "Epoch 12: Adversarial Loss - 1.377, Loss - 0.265\n",
      "Epoch 13: Adversarial Loss - 1.306, Loss - 0.23\n",
      "Epoch 14: Adversarial Loss - 1.242, Loss - 0.202\n",
      "Epoch 15: Adversarial Loss - 1.201, Loss - 0.179\n",
      "Epoch 16: Adversarial Loss - 1.147, Loss - 0.159\n",
      "Epoch 17: Adversarial Loss - 1.115, Loss - 0.143\n",
      "Epoch 18: Adversarial Loss - 1.064, Loss - 0.13\n",
      "Epoch 19: Adversarial Loss - 1.036, Loss - 0.117\n",
      "Epoch 20: Adversarial Loss - 1.001, Loss - 0.106\n",
      "Epoch 21: Adversarial Loss - 0.96, Loss - 0.098\n",
      "Epoch 22: Adversarial Loss - 0.955, Loss - 0.089\n",
      "Epoch 23: Adversarial Loss - 0.907, Loss - 0.081\n",
      "Epoch 24: Adversarial Loss - 0.901, Loss - 0.076\n",
      "Epoch 25: Adversarial Loss - 0.86, Loss - 0.069\n",
      "Epoch 26: Adversarial Loss - 0.838, Loss - 0.065\n",
      "Epoch 27: Adversarial Loss - 0.804, Loss - 0.06\n",
      "Epoch 28: Adversarial Loss - 0.777, Loss - 0.056\n",
      "Epoch 29: Adversarial Loss - 0.79, Loss - 0.052\n",
      "Epoch 30: Adversarial Loss - 0.771, Loss - 0.05\n",
      "Epoch 31: Adversarial Loss - 0.751, Loss - 0.047\n",
      "Epoch 32: Adversarial Loss - 0.73, Loss - 0.044\n",
      "Epoch 33: Adversarial Loss - 0.727, Loss - 0.042\n",
      "Epoch 34: Adversarial Loss - 0.709, Loss - 0.039\n",
      "Epoch 35: Adversarial Loss - 0.68, Loss - 0.037\n",
      "Epoch 36: Adversarial Loss - 0.683, Loss - 0.036\n",
      "Epoch 37: Adversarial Loss - 0.661, Loss - 0.033\n",
      "Epoch 38: Adversarial Loss - 0.652, Loss - 0.032\n",
      "Epoch 39: Adversarial Loss - 0.638, Loss - 0.03\n",
      "Epoch 40: Adversarial Loss - 0.627, Loss - 0.029\n",
      "Epoch 41: Adversarial Loss - 0.629, Loss - 0.027\n",
      "Epoch 42: Adversarial Loss - 0.617, Loss - 0.026\n",
      "Epoch 43: Adversarial Loss - 0.585, Loss - 0.025\n",
      "Epoch 44: Adversarial Loss - 0.603, Loss - 0.024\n",
      "Epoch 45: Adversarial Loss - 0.59, Loss - 0.023\n",
      "Epoch 46: Adversarial Loss - 0.573, Loss - 0.022\n",
      "Epoch 47: Adversarial Loss - 0.557, Loss - 0.021\n",
      "Epoch 48: Adversarial Loss - 0.546, Loss - 0.02\n",
      "Epoch 49: Adversarial Loss - 0.567, Loss - 0.02\n",
      "Epoch 50: Adversarial Loss - 0.526, Loss - 0.019\n",
      "Epoch 51: Adversarial Loss - 0.547, Loss - 0.018\n",
      "Epoch 52: Adversarial Loss - 0.527, Loss - 0.017\n",
      "Epoch 53: Adversarial Loss - 0.517, Loss - 0.017\n",
      "Epoch 54: Adversarial Loss - 0.518, Loss - 0.016\n",
      "Epoch 55: Adversarial Loss - 0.515, Loss - 0.016\n",
      "Epoch 56: Adversarial Loss - 0.496, Loss - 0.015\n",
      "Epoch 57: Adversarial Loss - 0.507, Loss - 0.015\n",
      "Epoch 58: Adversarial Loss - 0.471, Loss - 0.014\n",
      "Epoch 59: Adversarial Loss - 0.489, Loss - 0.014\n",
      "Epoch 60: Adversarial Loss - 0.494, Loss - 0.013\n",
      "Epoch 61: Adversarial Loss - 0.466, Loss - 0.013\n",
      "Epoch 62: Adversarial Loss - 0.453, Loss - 0.012\n",
      "Epoch 63: Adversarial Loss - 0.452, Loss - 0.012\n",
      "Epoch 64: Adversarial Loss - 0.465, Loss - 0.012\n",
      "Epoch 65: Adversarial Loss - 0.462, Loss - 0.011\n",
      "Epoch 66: Adversarial Loss - 0.46, Loss - 0.011\n",
      "Epoch 67: Adversarial Loss - 0.436, Loss - 0.011\n",
      "Epoch 68: Adversarial Loss - 0.443, Loss - 0.011\n",
      "Epoch 69: Adversarial Loss - 0.443, Loss - 0.01\n",
      "Epoch 70: Adversarial Loss - 0.436, Loss - 0.01\n",
      "Epoch 71: Adversarial Loss - 0.443, Loss - 0.01\n",
      "Epoch 72: Adversarial Loss - 0.424, Loss - 0.009\n",
      "Epoch 73: Adversarial Loss - 0.411, Loss - 0.009\n",
      "Epoch 74: Adversarial Loss - 0.407, Loss - 0.008\n",
      "Epoch 75: Adversarial Loss - 0.402, Loss - 0.009\n",
      "Epoch 76: Adversarial Loss - 0.41, Loss - 0.008\n",
      "Epoch 77: Adversarial Loss - 0.419, Loss - 0.008\n",
      "Epoch 78: Adversarial Loss - 0.391, Loss - 0.008\n",
      "Epoch 79: Adversarial Loss - 0.406, Loss - 0.008\n",
      "Epoch 80: Adversarial Loss - 0.379, Loss - 0.008\n",
      "Epoch 81: Adversarial Loss - 0.382, Loss - 0.007\n",
      "Epoch 82: Adversarial Loss - 0.385, Loss - 0.007\n",
      "Epoch 83: Adversarial Loss - 0.385, Loss - 0.007\n",
      "Epoch 84: Adversarial Loss - 0.363, Loss - 0.007\n",
      "Epoch 85: Adversarial Loss - 0.386, Loss - 0.007\n",
      "Epoch 86: Adversarial Loss - 0.378, Loss - 0.007\n",
      "Epoch 87: Adversarial Loss - 0.364, Loss - 0.006\n",
      "Epoch 88: Adversarial Loss - 0.377, Loss - 0.007\n",
      "Epoch 89: Adversarial Loss - 0.347, Loss - 0.006\n",
      "Epoch 90: Adversarial Loss - 0.358, Loss - 0.006\n",
      "Epoch 91: Adversarial Loss - 0.364, Loss - 0.006\n",
      "Epoch 92: Adversarial Loss - 0.35, Loss - 0.006\n",
      "Epoch 93: Adversarial Loss - 0.36, Loss - 0.006\n",
      "Epoch 94: Adversarial Loss - 0.353, Loss - 0.006\n",
      "Epoch 95: Adversarial Loss - 0.348, Loss - 0.005\n",
      "Epoch 96: Adversarial Loss - 0.337, Loss - 0.005\n",
      "Epoch 97: Adversarial Loss - 0.355, Loss - 0.005\n",
      "Epoch 98: Adversarial Loss - 0.351, Loss - 0.005\n",
      "Epoch 99: Adversarial Loss - 0.327, Loss - 0.005\n",
      "Epoch 100: Adversarial Loss - 0.33, Loss - 0.005\n",
      "Epoch 101: Adversarial Loss - 0.333, Loss - 0.005\n",
      "Epoch 102: Adversarial Loss - 0.324, Loss - 0.005\n",
      "Epoch 103: Adversarial Loss - 0.33, Loss - 0.005\n",
      "Epoch 104: Adversarial Loss - 0.321, Loss - 0.004\n",
      "Epoch 105: Adversarial Loss - 0.322, Loss - 0.005\n",
      "Epoch 106: Adversarial Loss - 0.328, Loss - 0.004\n",
      "Epoch 107: Adversarial Loss - 0.318, Loss - 0.004\n",
      "Epoch 108: Adversarial Loss - 0.31, Loss - 0.004\n",
      "Epoch 109: Adversarial Loss - 0.309, Loss - 0.004\n",
      "Epoch 110: Adversarial Loss - 0.313, Loss - 0.004\n",
      "Epoch 111: Adversarial Loss - 0.303, Loss - 0.004\n",
      "Epoch 112: Adversarial Loss - 0.305, Loss - 0.004\n",
      "Epoch 113: Adversarial Loss - 0.306, Loss - 0.004\n",
      "Epoch 114: Adversarial Loss - 0.306, Loss - 0.004\n",
      "Epoch 115: Adversarial Loss - 0.299, Loss - 0.004\n",
      "Epoch 116: Adversarial Loss - 0.299, Loss - 0.004\n",
      "Epoch 117: Adversarial Loss - 0.299, Loss - 0.004\n",
      "Epoch 118: Adversarial Loss - 0.291, Loss - 0.004\n",
      "Epoch 119: Adversarial Loss - 0.303, Loss - 0.003\n",
      "Epoch 120: Adversarial Loss - 0.287, Loss - 0.003\n",
      "Epoch 121: Adversarial Loss - 0.298, Loss - 0.004\n",
      "Epoch 122: Adversarial Loss - 0.276, Loss - 0.003\n",
      "Epoch 123: Adversarial Loss - 0.279, Loss - 0.003\n",
      "Epoch 124: Adversarial Loss - 0.294, Loss - 0.003\n",
      "Epoch 125: Adversarial Loss - 0.278, Loss - 0.003\n",
      "Epoch 126: Adversarial Loss - 0.271, Loss - 0.003\n",
      "Epoch 127: Adversarial Loss - 0.281, Loss - 0.003\n",
      "Epoch 128: Adversarial Loss - 0.278, Loss - 0.003\n",
      "Epoch 129: Adversarial Loss - 0.277, Loss - 0.003\n",
      "Epoch 130: Adversarial Loss - 0.271, Loss - 0.003\n",
      "Epoch 131: Adversarial Loss - 0.273, Loss - 0.003\n",
      "Epoch 132: Adversarial Loss - 0.266, Loss - 0.003\n",
      "Epoch 133: Adversarial Loss - 0.277, Loss - 0.003\n",
      "Epoch 134: Adversarial Loss - 0.278, Loss - 0.003\n",
      "Epoch 135: Adversarial Loss - 0.266, Loss - 0.003\n",
      "Epoch 136: Adversarial Loss - 0.265, Loss - 0.003\n",
      "Epoch 137: Adversarial Loss - 0.256, Loss - 0.003\n",
      "Epoch 138: Adversarial Loss - 0.264, Loss - 0.003\n",
      "Epoch 139: Adversarial Loss - 0.254, Loss - 0.003\n",
      "Epoch 140: Adversarial Loss - 0.254, Loss - 0.003\n",
      "Epoch 141: Adversarial Loss - 0.263, Loss - 0.003\n",
      "Epoch 142: Adversarial Loss - 0.25, Loss - 0.003\n",
      "Epoch 143: Adversarial Loss - 0.257, Loss - 0.002\n",
      "Epoch 144: Adversarial Loss - 0.259, Loss - 0.002\n",
      "Epoch 145: Adversarial Loss - 0.243, Loss - 0.002\n",
      "Epoch 146: Adversarial Loss - 0.245, Loss - 0.002\n",
      "Epoch 147: Adversarial Loss - 0.247, Loss - 0.002\n",
      "Epoch 148: Adversarial Loss - 0.246, Loss - 0.002\n",
      "Epoch 149: Adversarial Loss - 0.244, Loss - 0.002\n",
      "Epoch 150: Adversarial Loss - 0.247, Loss - 0.002\n",
      "Epoch 151: Adversarial Loss - 0.246, Loss - 0.002\n",
      "Epoch 152: Adversarial Loss - 0.241, Loss - 0.002\n",
      "Epoch 153: Adversarial Loss - 0.24, Loss - 0.002\n",
      "Epoch 154: Adversarial Loss - 0.236, Loss - 0.002\n",
      "Epoch 155: Adversarial Loss - 0.235, Loss - 0.002\n",
      "Epoch 156: Adversarial Loss - 0.231, Loss - 0.002\n",
      "Epoch 157: Adversarial Loss - 0.238, Loss - 0.002\n",
      "Epoch 158: Adversarial Loss - 0.233, Loss - 0.002\n",
      "Epoch 159: Adversarial Loss - 0.231, Loss - 0.002\n",
      "Epoch 160: Adversarial Loss - 0.231, Loss - 0.002\n",
      "Epoch 161: Adversarial Loss - 0.228, Loss - 0.002\n",
      "Epoch 162: Adversarial Loss - 0.228, Loss - 0.002\n",
      "Epoch 163: Adversarial Loss - 0.222, Loss - 0.002\n",
      "Epoch 164: Adversarial Loss - 0.224, Loss - 0.002\n",
      "Epoch 165: Adversarial Loss - 0.219, Loss - 0.002\n",
      "Epoch 166: Adversarial Loss - 0.227, Loss - 0.002\n",
      "Epoch 167: Adversarial Loss - 0.215, Loss - 0.002\n",
      "Epoch 168: Adversarial Loss - 0.231, Loss - 0.002\n",
      "Epoch 169: Adversarial Loss - 0.217, Loss - 0.002\n",
      "Epoch 170: Adversarial Loss - 0.232, Loss - 0.002\n",
      "Epoch 171: Adversarial Loss - 0.218, Loss - 0.002\n",
      "Epoch 172: Adversarial Loss - 0.221, Loss - 0.002\n",
      "Epoch 173: Adversarial Loss - 0.21, Loss - 0.002\n",
      "Epoch 174: Adversarial Loss - 0.22, Loss - 0.002\n",
      "Epoch 175: Adversarial Loss - 0.22, Loss - 0.002\n",
      "Epoch 176: Adversarial Loss - 0.213, Loss - 0.002\n",
      "Epoch 177: Adversarial Loss - 0.214, Loss - 0.002\n",
      "Epoch 178: Adversarial Loss - 0.213, Loss - 0.002\n",
      "Epoch 179: Adversarial Loss - 0.224, Loss - 0.002\n",
      "Epoch 180: Adversarial Loss - 0.207, Loss - 0.002\n",
      "Epoch 181: Adversarial Loss - 0.206, Loss - 0.002\n",
      "Epoch 182: Adversarial Loss - 0.213, Loss - 0.002\n",
      "Epoch 183: Adversarial Loss - 0.209, Loss - 0.001\n",
      "Epoch 184: Adversarial Loss - 0.209, Loss - 0.001\n",
      "Epoch 185: Adversarial Loss - 0.206, Loss - 0.001\n",
      "Epoch 186: Adversarial Loss - 0.194, Loss - 0.001\n",
      "Epoch 187: Adversarial Loss - 0.204, Loss - 0.001\n",
      "Epoch 188: Adversarial Loss - 0.204, Loss - 0.001\n",
      "Epoch 189: Adversarial Loss - 0.205, Loss - 0.001\n",
      "Epoch 190: Adversarial Loss - 0.199, Loss - 0.001\n",
      "Epoch 191: Adversarial Loss - 0.205, Loss - 0.001\n",
      "Epoch 192: Adversarial Loss - 0.196, Loss - 0.001\n",
      "Epoch 193: Adversarial Loss - 0.197, Loss - 0.001\n",
      "Epoch 194: Adversarial Loss - 0.198, Loss - 0.001\n",
      "Epoch 195: Adversarial Loss - 0.204, Loss - 0.001\n",
      "Epoch 196: Adversarial Loss - 0.206, Loss - 0.001\n",
      "Epoch 197: Adversarial Loss - 0.196, Loss - 0.001\n",
      "Epoch 198: Adversarial Loss - 0.197, Loss - 0.001\n",
      "Epoch 199: Adversarial Loss - 0.198, Loss - 0.001\n",
      "Epoch 200: Adversarial Loss - 0.195, Loss - 0.001\n",
      "Epoch 201: Adversarial Loss - 0.198, Loss - 0.001\n",
      "Epoch 202: Adversarial Loss - 0.186, Loss - 0.001\n",
      "Epoch 203: Adversarial Loss - 0.196, Loss - 0.001\n",
      "Epoch 204: Adversarial Loss - 0.195, Loss - 0.001\n",
      "Epoch 205: Adversarial Loss - 0.193, Loss - 0.001\n",
      "Epoch 206: Adversarial Loss - 0.195, Loss - 0.001\n",
      "Epoch 207: Adversarial Loss - 0.18, Loss - 0.001\n",
      "Epoch 208: Adversarial Loss - 0.18, Loss - 0.001\n",
      "Epoch 209: Adversarial Loss - 0.19, Loss - 0.001\n",
      "Epoch 210: Adversarial Loss - 0.185, Loss - 0.001\n",
      "Epoch 211: Adversarial Loss - 0.181, Loss - 0.001\n",
      "Epoch 212: Adversarial Loss - 0.185, Loss - 0.001\n",
      "Epoch 213: Adversarial Loss - 0.182, Loss - 0.001\n",
      "Epoch 214: Adversarial Loss - 0.175, Loss - 0.001\n",
      "Epoch 215: Adversarial Loss - 0.18, Loss - 0.001\n",
      "Epoch 216: Adversarial Loss - 0.184, Loss - 0.001\n",
      "Epoch 217: Adversarial Loss - 0.184, Loss - 0.001\n",
      "Epoch 218: Adversarial Loss - 0.174, Loss - 0.001\n",
      "Epoch 219: Adversarial Loss - 0.185, Loss - 0.001\n",
      "Epoch 220: Adversarial Loss - 0.185, Loss - 0.001\n",
      "Epoch 221: Adversarial Loss - 0.182, Loss - 0.001\n",
      "Epoch 222: Adversarial Loss - 0.182, Loss - 0.001\n",
      "Epoch 223: Adversarial Loss - 0.17, Loss - 0.001\n",
      "Epoch 224: Adversarial Loss - 0.175, Loss - 0.001\n",
      "Epoch 225: Adversarial Loss - 0.182, Loss - 0.001\n",
      "Epoch 226: Adversarial Loss - 0.181, Loss - 0.001\n",
      "Epoch 227: Adversarial Loss - 0.176, Loss - 0.001\n",
      "Epoch 228: Adversarial Loss - 0.173, Loss - 0.001\n",
      "Epoch 229: Adversarial Loss - 0.172, Loss - 0.001\n",
      "Epoch 230: Adversarial Loss - 0.167, Loss - 0.001\n",
      "Epoch 231: Adversarial Loss - 0.177, Loss - 0.001\n",
      "Epoch 232: Adversarial Loss - 0.179, Loss - 0.001\n",
      "Epoch 233: Adversarial Loss - 0.169, Loss - 0.001\n",
      "Epoch 234: Adversarial Loss - 0.169, Loss - 0.001\n",
      "Epoch 235: Adversarial Loss - 0.162, Loss - 0.001\n",
      "Epoch 236: Adversarial Loss - 0.166, Loss - 0.001\n",
      "Epoch 237: Adversarial Loss - 0.171, Loss - 0.001\n",
      "Epoch 238: Adversarial Loss - 0.17, Loss - 0.001\n",
      "Epoch 239: Adversarial Loss - 0.165, Loss - 0.001\n",
      "Epoch 240: Adversarial Loss - 0.165, Loss - 0.001\n",
      "Epoch 241: Adversarial Loss - 0.174, Loss - 0.001\n",
      "Epoch 242: Adversarial Loss - 0.168, Loss - 0.001\n",
      "Epoch 243: Adversarial Loss - 0.16, Loss - 0.001\n",
      "Epoch 244: Adversarial Loss - 0.162, Loss - 0.001\n",
      "Epoch 245: Adversarial Loss - 0.172, Loss - 0.001\n",
      "Epoch 246: Adversarial Loss - 0.158, Loss - 0.001\n",
      "Epoch 247: Adversarial Loss - 0.169, Loss - 0.001\n",
      "Epoch 248: Adversarial Loss - 0.162, Loss - 0.001\n",
      "Epoch 249: Adversarial Loss - 0.17, Loss - 0.001\n",
      "Epoch 250: Adversarial Loss - 0.164, Loss - 0.001\n",
      "Epoch 251: Adversarial Loss - 0.163, Loss - 0.001\n",
      "Epoch 252: Adversarial Loss - 0.16, Loss - 0.001\n",
      "Epoch 253: Adversarial Loss - 0.153, Loss - 0.001\n",
      "Epoch 254: Adversarial Loss - 0.159, Loss - 0.001\n",
      "Epoch 255: Adversarial Loss - 0.16, Loss - 0.001\n",
      "Total finished in 386.55 minutes\n"
     ]
    }
   ],
   "source": [
    "start_total = time.perf_counter()\n",
    "\n",
    "for i in range(num_epochs):\n",
    "  running_loss_adv = 0\n",
    "  running_loss = 0\n",
    "  for batch, (data, labels) in enumerate(train_cifar_loader):\n",
    "    data = data.to(device)\n",
    "    labels = labels.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    data_mod, standard_loss = adversarial_update(data,labels, vgg11_adv,criterion, epsilon=.0625, step_size=.01, n_iter=7)\n",
    "    running_loss += standard_loss\n",
    "    preds = vgg11_adv(data_mod)\n",
    "    loss = criterion(preds, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    running_loss_adv += loss.item()\n",
    "    batches = batch+1\n",
    "  loss_standard[i] = running_loss/batches\n",
    "  loss_adv[i] = running_loss_adv/batches\n",
    "  print(\"Epoch \"+str(i)+\": Adversarial Loss - \"+str(round(loss_adv[i],3))+\", Loss - \"+str(round(loss_standard[i],3)))\n",
    "\n",
    "\n",
    "finish_total = time.perf_counter()\n",
    "\n",
    "print(f'Total finished in {round((finish_total-start_total)/60, 2)} minutes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f023ff4-f3bc-4112-88f6-af2c88d490bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(vgg11_adv.state_dict(), \"/nas/longleaf/home/judychao/STOR566/vgg11_adv_256.pt\")\n",
    "vgg11_adv.load_state_dict(torch.load(\"/nas/longleaf/home/judychao/STOR566/vgg11_adv_256.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48f68cb-a0bb-483a-9b31-7faad47d1edf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
